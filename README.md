# BENVISION
## BEN stands for Binaural Experience Navigator. We enable visually impaired individuals to experience the world around them through a combination of state of the art real time Machine Learning algorithm and Augmented Reality. We give them the ability to see objects through artificial intelligence and then convert those objects into soundscapes. Interestingly, Ben is also the name of the blind American diagnosed with retinal cancer who taught himself echolocation and was able to detect the location of objects by making frequent clicking noises with his tongue.

## How it works?

# Our solution uses an augmented reality camera, enhanced with a real-time machine learning algorithm and then converts those objects into a harmonious soundscape. Every stationary object in the environment is then associated with a unique chord, providing a one-of-a-kind beautiful interactive synesthetic experience.

## View our project at https://heroic-croissant-9334b4.netlify.app/

![Screenshot](screen.png)

### Projects used
AI - Yolo : https://github.com/wojciechp6/YOLO-UnityBarracuda
UnityNativeCamera:  https://github.com/yasirkula/UnityNativeCamera
ChatGPT to solve some problems ;)

### 2020
Toolchain:
* Android Studio 4.0.1
* Android SDK 9.0 (API 28) Rev 6
* Android NDK (Side by side) 21.3.6528147
* CMake 3.4.1
* Unity Hub 2.3.2
* Unity 2020.3.35f1
* Qualcomm Snapdragon Spaces 0.9.0
* AI - Unity Barracuda 1.0.4

## Troubleshooting

If you have trouble building the Unity project, please try the following:
```
Open "Build Settings" and make sure that you have switched to the "Android" platform.

This should allow you to build successfully.
```
